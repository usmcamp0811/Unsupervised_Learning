{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_pixels = 28*28\n",
    "latent_dim = 20\n",
    "h_dim = 512\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=([None, n_pixels]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape, name):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "def FC_layer(X, W, b):\n",
    "    return tf.matmul(X, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder\n",
    "with tf.name_scope('Encoder'):\n",
    "    with tf.name_scope('Layer_1'):\n",
    "        W_enc = weight_variable([n_pixels, h_dim], 'W_enc')\n",
    "        b_enc = bias_variable([h_dim], 'b_enc')\n",
    "        h_enc = tf.nn.tanh(FC_layer(X, W_enc, b_enc))\n",
    "\n",
    "    with tf.name_scope('Layer_2'):\n",
    "        W_mu = weight_variable([h_dim, latent_dim], 'W_enc')\n",
    "        b_mu = bias_variable([latent_dim], 'b_enc')\n",
    "        mu = FC_layer(h_enc, W_mu, b_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Latent Space\n",
    "with tf.name_scope('Latent_Space'):   \n",
    "    with tf.name_scope('Log_Std'):\n",
    "        W_logstd = weight_variable([h_dim, latent_dim], 'W_logstd')\n",
    "        b_logstd = bias_variable([latent_dim], 'b_logstd')\n",
    "        logstd = FC_layer(h_enc, W_logstd, b_logstd)\n",
    "    \n",
    "    with tf.name_scope('Z'):\n",
    "        noise = tf.random_normal([1, latent_dim])\n",
    "        z = mu + tf.multiply(noise, tf.exp(.5*logstd))\n",
    "\n",
    "        tf.summary.histogram('mu', mu)\n",
    "        tf.summary.histogram('z', z)\n",
    "        tf.summary.histogram('W_logstd', W_logstd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Decoder\n",
    "with tf.name_scope('Decoder'):\n",
    "    with tf.name_scope('Layer_1'):\n",
    "        W_dec = weight_variable([latent_dim, h_dim], 'W_dec')\n",
    "        b_dec = bias_variable([h_dim], 'b_dec')\n",
    "        h_dec = tf.nn.tanh(FC_layer(z, W_dec, b_dec))\n",
    "    \n",
    "    with tf.name_scope('Layer_2'):\n",
    "        W_reconstruct = weight_variable([h_dim, n_pixels], 'W_reconstruct')\n",
    "        b_reconstruct = bias_variable([n_pixels], 'b_reconstruct')\n",
    "        reconstruction = tf.nn.sigmoid(FC_layer(h_dec, W_reconstruct, b_reconstruct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss Function\n",
    "with tf.name_scope('Loss_Function'):\n",
    "    log_likelihood = tf.reduce_sum(X*tf.log(reconstruction + 1e-9)+(1 - X)\\\n",
    "                                   *tf.log(1 -reconstruction + 1e-9), \\\n",
    "                                   reduction_indices=1)\n",
    "    KL_term = -.5*tf.reduce_sum(1 + 2 *logstd - tf.pow(mu,2) - tf.exp(2*logstd),\\\n",
    "                               reduction_indices=1)\n",
    "    variational_lower_bound = tf.reduce_mean(log_likelihood - KL_term)\n",
    "    optimizer = tf.train.AdadeltaOptimizer().minimize(-variational_lower_bound)\n",
    "    \n",
    "    KL_mean = tf.reduce_mean(KL_term)\n",
    "    LogL_mean = tf.reduce_mean(log_likelihood)\n",
    "    VLB_mean = tf.reduce_mean(variational_lower_bound)\n",
    "    tf.summary.scalar('Log_Likelihood', LogL_mean)\n",
    "    tf.summary.scalar('KL_term', KL_mean)\n",
    "    tf.summary.scalar('Variational_Lower_Bound', VLB_mean)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "writer = tf.summary.FileWriter('./train', sess.graph)\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 8590, Loss: -550.6430664062575\r"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "batch_size = 1024\n",
    "\n",
    "for i in range(epochs):\n",
    "    x_batch = np.round(mnist.train.next_batch(batch_size)[0])\n",
    "    merged = tf.summary.merge_all()\n",
    "    opt, summary, vlb_eval = sess.run((optimizer, merged, variational_lower_bound), feed_dict={X: x_batch})\n",
    "    print(\"Iteration: {}, Loss: {}\".format(i, vlb_eval), end='\\r')\n",
    "    writer.add_summary(summary, i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
